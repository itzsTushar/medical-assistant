from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_groq import ChatGroq
import os
from dotenv import load_dotenv

load_dotenv()

GROQ_API_KEY=os.getenv("GROQ_API_KEY")

def get_llm_chain(retriever):
    # Initialize Groq LLM
    llm = ChatGroq(
        api_key=GROQ_API_KEY,
        model="llama-3.3-70b-versatile",
        temperature=0
    )

    # Define your custom medical prompt
    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template="""
You are **MediBot**, an AI-powered assistant trained to help users understand medical documents and health-related questions. 
Your job is to provide clear, accurate, and helpful responses based **only on the provided context**.

---

**Context:**
{context}

**User Question:**
{question}

---

**Answer:**
- Respond in a calm, factual, and respectful tone.  
- Use simple explanations when needed.  
- If the context does not contain the answer, say:  
  "I'm sorry, but I couldn't find relevant information in the provided documents."  
- Do not make up facts.  
- Do not give medical advice or diagnoses.
"""
    )

    # Build the RetrievalQA chain
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True
    )

